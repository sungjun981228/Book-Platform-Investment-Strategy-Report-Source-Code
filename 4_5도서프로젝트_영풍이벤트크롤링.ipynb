{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf6a582b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, time, os, pandas as pd\n",
    "\n",
    "def crawl_event_page(url, max_pages=10):\n",
    "    save_dir = \".\"  # ì´ë¯¸ì§€ ì €ì¥ ìœ„ì¹˜: í˜„ì¬ ë…¸íŠ¸ë¶ í´ë”\n",
    "    driver = webdriver.Chrome()\n",
    "    driver.get(url)\n",
    "    wait = WebDriverWait(driver, 5)\n",
    "\n",
    "    data = []\n",
    "    image_count = 1\n",
    "\n",
    "    try:\n",
    "        for page_num in range(1, max_pages + 1):\n",
    "            print(f\"ğŸ“„ {page_num}í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘... (í˜„ì¬ ì´ë¯¸ì§€ ìˆ˜: {image_count - 1})\")\n",
    "            time.sleep(2)\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            event_blocks = soup.select('li.event_item')\n",
    "\n",
    "            for block in event_blocks:\n",
    "                name_tag = block.select_one('h1.book__title')\n",
    "                period_tag = block.select_one('p.book__author.text_green')\n",
    "                img_tag = block.select_one('img.event_list_img')\n",
    "\n",
    "                if not (name_tag and period_tag and img_tag):\n",
    "                    continue\n",
    "\n",
    "                event_name = name_tag.get_text(strip=True)\n",
    "                period = period_tag.get_text(strip=True)\n",
    "                img_url = img_tag.get('src') or img_tag.get('data-src')\n",
    "\n",
    "                if not img_url:\n",
    "                    continue\n",
    "\n",
    "                if img_url.startswith('//'):\n",
    "                    img_url = 'https:' + img_url\n",
    "                elif img_url.startswith('/'):\n",
    "                    base_url = '/'.join(url.split('/')[:3])\n",
    "                    img_url = base_url + img_url\n",
    "\n",
    "                img_name = f\"image_{image_count:03d}.jpg\"\n",
    "                try:\n",
    "                    res = requests.get(img_url)\n",
    "                    if res.status_code == 200:\n",
    "                        with open(os.path.join(save_dir, img_name), 'wb') as f:\n",
    "                            f.write(res.content)\n",
    "                        print(f\"ğŸ“¸ ì €ì¥ë¨: {img_name}\")\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {img_url}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "                data.append({\n",
    "                    'ì´ë¯¸ì§€ëª…': img_name,\n",
    "                    'ì´ë²¤íŠ¸ëª…': event_name,\n",
    "                    'ì¦ì •í’ˆ': '',\n",
    "                    'ê¸°ê°„': period\n",
    "                })\n",
    "                image_count += 1\n",
    "\n",
    "            # ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ í´ë¦­\n",
    "            try:\n",
    "                next_xpath = f'//*[@id=\"content\"]/div[2]/div[2]/div/div[2]/div/div/div/div/ul/li[{page_num+1}]/a'\n",
    "                next_btn = wait.until(EC.element_to_be_clickable((By.XPATH, next_xpath)))\n",
    "                next_btn.click()\n",
    "            except:\n",
    "                print(\"ğŸ“Œ ë‹¤ìŒ í˜ì´ì§€ ì—†ìŒ ë˜ëŠ” í´ë¦­ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "        df = pd.DataFrame(data)\n",
    "        df = df[['ì´ë¯¸ì§€ëª…', 'ì´ë²¤íŠ¸ëª…', 'ì¦ì •í’ˆ', 'ê¸°ê°„']]\n",
    "        df.to_csv('ì´ë²¤íŠ¸ì •ë³´.csv', index=False, encoding='utf-8-sig')\n",
    "        print(f\"\\nâœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(df)}ê±´ ì €ì¥ â†’ ì´ë²¤íŠ¸ì •ë³´.csv\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "crawl_event_page(\"https://www.ypbooks.co.kr/event/online/event-list?status=1\", max_pages=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dc4745",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from bs4 import BeautifulSoup\n",
    "import requests, time, os, pandas as pd\n",
    "\n",
    "def crawl_event_page(url):\n",
    "    save_dir = \".\"\n",
    "    \n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    # options.add_argument('--headless')\n",
    "    \n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    driver.get(url)\n",
    "    time.sleep(5)\n",
    "\n",
    "    data = []\n",
    "    image_count = 24\n",
    "    max_pages = 50\n",
    "    processed_pages = set()\n",
    "    consecutive_failures = 0  # ì—°ì† ì‹¤íŒ¨ íšŸìˆ˜ ì¶”ì \n",
    "\n",
    "    def get_current_page(driver):\n",
    "        try:\n",
    "            # HTML êµ¬ì¡°ì— ë§ëŠ” ì •í™•í•œ ì„ íƒìë“¤\n",
    "            selectors = [\n",
    "                'a[aria-current=\"page\"]',  # ê°€ì¥ ì •í™•í•œ ì„ íƒì (HTMLì—ì„œ í™•ì¸ë¨)\n",
    "                'a.pagination_page[aria-current=\"page\"]',\n",
    "                '.pagination .active',\n",
    "                '.pagination .current',\n",
    "                'strong.num'\n",
    "            ]\n",
    "            \n",
    "            for selector in selectors:\n",
    "                try:\n",
    "                    el = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                    page_text = el.text.strip()\n",
    "                    print(f\"ğŸ” í˜ì´ì§€ í…ìŠ¤íŠ¸ ë°œê²¬: '{page_text}' (ì„ íƒì: {selector})\")\n",
    "                    if page_text.isdigit():\n",
    "                        return int(page_text)\n",
    "                except Exception as sel_e:\n",
    "                    print(f\"âš ï¸ ì„ íƒì {selector} ì‹¤íŒ¨: {sel_e}\")\n",
    "                    continue\n",
    "            \n",
    "            # XPathë¡œë„ ì‹œë„\n",
    "            xpath_selectors = [\n",
    "                '//*[@aria-current=\"page\"]',\n",
    "                '//a[@aria-current=\"page\"]',\n",
    "                '//strong[contains(@class, \"num\")]'\n",
    "            ]\n",
    "            \n",
    "            for xpath in xpath_selectors:\n",
    "                try:\n",
    "                    el = driver.find_element(By.XPATH, xpath)\n",
    "                    page_text = el.text.strip()\n",
    "                    print(f\"ğŸ” XPathë¡œ í˜ì´ì§€ í…ìŠ¤íŠ¸ ë°œê²¬: '{page_text}' (XPath: {xpath})\")\n",
    "                    if page_text.isdigit():\n",
    "                        return int(page_text)\n",
    "                except Exception as xpath_e:\n",
    "                    print(f\"âš ï¸ XPath {xpath} ì‹¤íŒ¨: {xpath_e}\")\n",
    "                    continue\n",
    "            \n",
    "            # ëª¨ë“  pagination_page ë§í¬ë¥¼ ì°¾ì•„ì„œ aria-currentê°€ ìˆëŠ” ê²ƒ ì°¾ê¸°\n",
    "            try:\n",
    "                all_page_links = driver.find_elements(By.CSS_SELECTOR, 'a.pagination_page, a[class*=\"pagination\"]')\n",
    "                print(f\"ğŸ” ì°¾ì€ í˜ì´ì§€ ë§í¬ ìˆ˜: {len(all_page_links)}\")\n",
    "                for link in all_page_links:\n",
    "                    aria_current = link.get_attribute('aria-current')\n",
    "                    if aria_current == 'page':\n",
    "                        page_text = link.text.strip()\n",
    "                        print(f\"ğŸ¯ aria-current='page' ë§í¬ ë°œê²¬: '{page_text}'\")\n",
    "                        if page_text.isdigit():\n",
    "                            return int(page_text)\n",
    "            except Exception as all_e:\n",
    "                print(f\"âš ï¸ ëª¨ë“  í˜ì´ì§€ ë§í¬ ê²€ì‚¬ ì‹¤íŒ¨: {all_e}\")\n",
    "            \n",
    "            print(\"âš ï¸ í˜„ì¬ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "            return 1  # ê¸°ë³¸ê°’ì„ 1ë¡œ ì„¤ì • (ëŒ€ì‹  -1)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í˜ì´ì§€ ë²ˆí˜¸ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}\")\n",
    "            return 1\n",
    "\n",
    "    def get_next_button(driver):\n",
    "        \"\"\"HTML êµ¬ì¡°ì— ë§ëŠ” ë‹¤ìŒ ë²„íŠ¼ ì°¾ê¸°\"\"\"\n",
    "        \n",
    "        # ë°©ë²• 1: pagination_btn--next í´ë˜ìŠ¤ë¡œ ë‹¤ìŒ ë²„íŠ¼ ì°¾ê¸° (ê°€ì¥ ì •í™•)\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.CSS_SELECTOR, 'a.pagination_btn.pagination_btn--next')\n",
    "            if next_btn.is_enabled() and next_btn.is_displayed():\n",
    "                # hrefê°€ javascript:;ê°€ ì•„ë‹Œì§€ í™•ì¸\n",
    "                href = next_btn.get_attribute('href')\n",
    "                if href and 'javascript:' not in href:\n",
    "                    print(\"âœ… pagination_btn--next ë‹¤ìŒ ë²„íŠ¼ ë°œê²¬\")\n",
    "                    return next_btn\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ë°©ë²• 2: aria-label=\"ë‹¤ìŒ\"ìœ¼ë¡œ ì°¾ê¸°\n",
    "        try:\n",
    "            next_btn = driver.find_element(By.XPATH, '//a[@aria-label=\"ë‹¤ìŒ\"]')\n",
    "            if next_btn.is_enabled() and next_btn.is_displayed():\n",
    "                print(\"âœ… aria-label='ë‹¤ìŒ' ë²„íŠ¼ ë°œê²¬\")\n",
    "                return next_btn\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ë°©ë²• 3: í˜„ì¬ í˜ì´ì§€ ë‹¤ìŒ ë²ˆí˜¸ ë§í¬ ì§ì ‘ ì°¾ê¸°\n",
    "        current_page = get_current_page(driver)\n",
    "        if current_page != -1:\n",
    "            next_page = current_page + 1\n",
    "            try:\n",
    "                # ì •í™•í•œ ì„ íƒìë¡œ ë‹¤ìŒ í˜ì´ì§€ ë§í¬ ì°¾ê¸°\n",
    "                next_page_link = driver.find_element(\n",
    "                    By.XPATH, f'//a[@class=\"pagination_page\" and text()=\"{next_page}\"]'\n",
    "                )\n",
    "                if next_page_link.is_enabled() and next_page_link.is_displayed():\n",
    "                    print(f\"âœ… í˜ì´ì§€ {next_page} ë§í¬ ë°œê²¬\")\n",
    "                    return next_page_link\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # ë°©ë²• 4: í˜„ì¬ í™œì„± í˜ì´ì§€ ì´í›„ì˜ ëª¨ë“  ìˆ«ì ë§í¬ ì¤‘ ì²« ë²ˆì§¸\n",
    "        try:\n",
    "            current_page = get_current_page(driver)\n",
    "            if current_page != -1:\n",
    "                all_page_links = driver.find_elements(By.CSS_SELECTOR, 'a.pagination_page')\n",
    "                for link in all_page_links:\n",
    "                    try:\n",
    "                        page_num = int(link.text.strip())\n",
    "                        if page_num == current_page + 1:\n",
    "                            if link.is_enabled() and link.is_displayed():\n",
    "                                print(f\"âœ… ë‹¤ìŒ í˜ì´ì§€ ({page_num}) ë§í¬ ë°œê²¬\")\n",
    "                                return link\n",
    "                    except:\n",
    "                        continue\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # ë°©ë²• 5: í˜ì´ì§€ë„¤ì´ì…˜ ì˜ì—­ì—ì„œ \"ë‹¤ìŒ\" í…ìŠ¤íŠ¸ ë˜ëŠ” > ê¸°í˜¸ ì°¾ê¸°\n",
    "        next_patterns = [\n",
    "            '//a[contains(@class, \"pagination\") and (contains(text(), \"ë‹¤ìŒ\") or contains(text(), \">\"))]',\n",
    "            '//*[contains(@class, \"pagination\")]//a[contains(@aria-label, \"ë‹¤ìŒ\")]',\n",
    "            '//*[contains(@class, \"pagination\")]//a[contains(@title, \"ë‹¤ìŒ\")]'\n",
    "        ]\n",
    "        \n",
    "        for pattern in next_patterns:\n",
    "            try:\n",
    "                btn = driver.find_element(By.XPATH, pattern)\n",
    "                if btn.is_enabled() and btn.is_displayed():\n",
    "                    print(\"âœ… íŒ¨í„´ ë§¤ì¹­ìœ¼ë¡œ ë‹¤ìŒ ë²„íŠ¼ ë°œê²¬\")\n",
    "                    return btn\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        return None\n",
    "\n",
    "    def click_next_safely(next_btn, driver):\n",
    "        \"\"\"JavaScript ê¸°ë°˜ í˜ì´ì§€ë„¤ì´ì…˜ì„ ìœ„í•œ íŠ¹ë³„í•œ í´ë¦­ ì²˜ë¦¬\"\"\"\n",
    "        try:\n",
    "            current_page = get_current_page(driver)\n",
    "            print(f\"ğŸ”„ í˜„ì¬ í˜ì´ì§€: {current_page}\")\n",
    "            \n",
    "            # ë²„íŠ¼ì´ í™”ë©´ì— ë³´ì´ë„ë¡ ìŠ¤í¬ë¡¤\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", next_btn)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # href ì†ì„± í™•ì¸\n",
    "            href = next_btn.get_attribute('href')\n",
    "            print(f\"ğŸ”— ë²„íŠ¼ href: {href}\")\n",
    "            \n",
    "            # onclick ì´ë²¤íŠ¸ë‚˜ ë‹¤ë¥¸ ì†ì„±ë“¤ë„ í™•ì¸\n",
    "            onclick = next_btn.get_attribute('onclick')\n",
    "            data_attrs = {\n",
    "                'data-page': next_btn.get_attribute('data-page'),\n",
    "                'data-url': next_btn.get_attribute('data-url'),\n",
    "                'data-href': next_btn.get_attribute('data-href')\n",
    "            }\n",
    "            print(f\"ğŸ”— onclick: {onclick}\")\n",
    "            print(f\"ğŸ”— data ì†ì„±ë“¤: {data_attrs}\")\n",
    "            \n",
    "            # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ í´ë¦­ ì‹œë„\n",
    "            success = False\n",
    "            \n",
    "            # ë°©ë²• 1: ë” ê°•ë ¥í•œ JavaScript í´ë¦­\n",
    "            try:\n",
    "                print(\"ğŸ‘† ë°©ë²• 1: ê°•ë ¥í•œ JavaScript í´ë¦­\")\n",
    "                # ì´ë²¤íŠ¸ ê°•ì œ ë°œìƒ\n",
    "                driver.execute_script(\"\"\"\n",
    "                    var element = arguments[0];\n",
    "                    var event = new MouseEvent('click', {\n",
    "                        view: window,\n",
    "                        bubbles: true,\n",
    "                        cancelable: true\n",
    "                    });\n",
    "                    element.dispatchEvent(event);\n",
    "                \"\"\", next_btn)\n",
    "                \n",
    "                # í˜ì´ì§€ ë³€ê²½ ëŒ€ê¸°\n",
    "                for i in range(12):\n",
    "                    time.sleep(1)\n",
    "                    new_page = get_current_page(driver)\n",
    "                    if new_page > current_page and new_page != current_page:\n",
    "                        print(f\"âœ… ë°©ë²• 1 ì„±ê³µ: {current_page} â†’ {new_page}\")\n",
    "                        return True\n",
    "                    if i % 3 == 0:\n",
    "                        print(f\"â³ ëŒ€ê¸° ì¤‘... ({i+1}/12ì´ˆ)\")\n",
    "                        \n",
    "            except Exception as e1:\n",
    "                print(f\"âŒ ë°©ë²• 1 ì‹¤íŒ¨: {e1}\")\n",
    "            \n",
    "            # ë°©ë²• 2: ì§ì ‘ í´ë¦­ + í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ ê°ì§€\n",
    "            try:\n",
    "                print(\"ğŸ‘† ë°©ë²• 2: ì§ì ‘ í´ë¦­\")\n",
    "                original_page_source_length = len(driver.page_source)\n",
    "                \n",
    "                next_btn.click()\n",
    "                \n",
    "                # í˜ì´ì§€ ë‚´ìš© ë³€ê²½ ê°ì§€\n",
    "                for i in range(10):\n",
    "                    time.sleep(1)\n",
    "                    new_page = get_current_page(driver)\n",
    "                    new_page_source_length = len(driver.page_source)\n",
    "                    \n",
    "                    # í˜ì´ì§€ ë²ˆí˜¸ê°€ ë³€ê²½ë˜ì—ˆê±°ë‚˜ í˜ì´ì§€ ë‚´ìš©ì´ í¬ê²Œ ë°”ë€Œì—ˆë‹¤ë©´\n",
    "                    if (new_page > current_page) or (abs(new_page_source_length - original_page_source_length) > 1000):\n",
    "                        print(f\"âœ… ë°©ë²• 2 ì„±ê³µ: {current_page} â†’ {new_page}\")\n",
    "                        return True\n",
    "                        \n",
    "            except Exception as e2:\n",
    "                print(f\"âŒ ë°©ë²• 2 ì‹¤íŒ¨: {e2}\")\n",
    "            \n",
    "            # ë°©ë²• 3: ë¸Œë¼ìš°ì € ê¸°ë³¸ ë™ì‘ ì‹œë®¬ë ˆì´ì…˜\n",
    "            try:\n",
    "                print(\"ğŸ‘† ë°©ë²• 3: ë¸Œë¼ìš°ì € ë™ì‘ ì‹œë®¬ë ˆì´ì…˜\")\n",
    "                from selenium.webdriver.common.action_chains import ActionChains\n",
    "                \n",
    "                actions = ActionChains(driver)\n",
    "                actions.move_to_element(next_btn).click().perform()\n",
    "                \n",
    "                for i in range(8):\n",
    "                    time.sleep(1)\n",
    "                    new_page = get_current_page(driver)\n",
    "                    if new_page > current_page:\n",
    "                        print(f\"âœ… ë°©ë²• 3 ì„±ê³µ: {current_page} â†’ {new_page}\")\n",
    "                        return True\n",
    "                        \n",
    "            except Exception as e3:\n",
    "                print(f\"âŒ ë°©ë²• 3 ì‹¤íŒ¨: {e3}\")\n",
    "            \n",
    "            # ë°©ë²• 4: ê°•ì œ í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ í›„ ë‹¤ìŒ í˜ì´ì§€ ë²ˆí˜¸ë¡œ ì´ë™ ì‹œë„\n",
    "            if current_page > 0:\n",
    "                try:\n",
    "                    print(\"ğŸ‘† ë°©ë²• 4: URL ì¡°ì‘ìœ¼ë¡œ ë‹¤ìŒ í˜ì´ì§€ ì´ë™\")\n",
    "                    current_url = driver.current_url\n",
    "                    \n",
    "                    # URLì— í˜ì´ì§€ íŒŒë¼ë¯¸í„°ê°€ ìˆëŠ”ì§€ í™•ì¸\n",
    "                    if 'page=' in current_url:\n",
    "                        import re\n",
    "                        new_url = re.sub(r'page=\\d+', f'page={current_page + 1}', current_url)\n",
    "                    else:\n",
    "                        # í˜ì´ì§€ íŒŒë¼ë¯¸í„° ì¶”ê°€\n",
    "                        separator = '&' if '?' in current_url else '?'\n",
    "                        new_url = f\"{current_url}{separator}page={current_page + 1}\"\n",
    "                    \n",
    "                    print(f\"ğŸš€ URL ì´ë™: {new_url}\")\n",
    "                    driver.get(new_url)\n",
    "                    time.sleep(5)\n",
    "                    \n",
    "                    final_page = get_current_page(driver)\n",
    "                    if final_page == current_page + 1:\n",
    "                        print(f\"âœ… ë°©ë²• 4 ì„±ê³µ: {current_page} â†’ {final_page}\")\n",
    "                        return True\n",
    "                        \n",
    "                except Exception as e4:\n",
    "                    print(f\"âŒ ë°©ë²• 4 ì‹¤íŒ¨: {e4}\")\n",
    "            \n",
    "            print(\"âŒ ëª¨ë“  í´ë¦­ ë°©ë²• ì‹¤íŒ¨\")\n",
    "            return False\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ í´ë¦­ ì²˜ë¦¬ ì¤‘ ì „ì²´ ì˜¤ë¥˜: {e}\")\n",
    "            return False\n",
    "\n",
    "    try:\n",
    "        page_count = 0\n",
    "        while page_count < max_pages:\n",
    "            cur_page = get_current_page(driver)\n",
    "            print(f\"\\nğŸ“„ {cur_page}í˜ì´ì§€ í¬ë¡¤ë§ ì¤‘... (í˜„ì¬ ì´ë¯¸ì§€ ìˆ˜: {image_count - 1})\")\n",
    "            \n",
    "            # ë¬´í•œë£¨í”„ ë°©ì§€: ì´ë¯¸ ì²˜ë¦¬í•œ í˜ì´ì§€ í™•ì¸\n",
    "            if cur_page != -1 and cur_page in processed_pages:\n",
    "                print(f\"âš ï¸ ì´ë¯¸ ì²˜ë¦¬í•œ í˜ì´ì§€({cur_page}) ê°ì§€. ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                break\n",
    "            \n",
    "            if cur_page > 0:  # ìœ íš¨í•œ í˜ì´ì§€ ë²ˆí˜¸ë§Œ ì¶”ê°€\n",
    "                processed_pages.add(cur_page)\n",
    "\n",
    "            # í˜ì´ì§€ ì™„ì „ ë¡œë”© ëŒ€ê¸°\n",
    "            wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \"li.event_item\")))\n",
    "            time.sleep(2)\n",
    "            \n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            event_blocks = soup.select('li.event_item')\n",
    "            \n",
    "            print(f\"ğŸ” ì°¾ì€ ì´ë²¤íŠ¸ ë¸”ë¡ ìˆ˜: {len(event_blocks)}\")\n",
    "            \n",
    "            if not event_blocks:\n",
    "                consecutive_failures += 1\n",
    "                if consecutive_failures >= 3:\n",
    "                    print(\"âš ï¸ ì—°ì†ìœ¼ë¡œ ì´ë²¤íŠ¸ ë¸”ë¡ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                    break\n",
    "                print(\"âš ï¸ ì´ë²¤íŠ¸ ë¸”ë¡ ì—†ìŒ. ë‹¤ìŒ í˜ì´ì§€ë¡œ...\")\n",
    "            else:\n",
    "                consecutive_failures = 0  # ì„±ê³µí•˜ë©´ ì‹¤íŒ¨ íšŸìˆ˜ ë¦¬ì…‹\n",
    "\n",
    "            # ë°ì´í„° ìˆ˜ì§‘\n",
    "            for i, block in enumerate(event_blocks):\n",
    "                name_tag = block.select_one('h1.book__title')\n",
    "                period_tag = block.select_one('p.book__author.text_green')\n",
    "                img_tag = block.select_one('img.event_list_img')\n",
    "\n",
    "                if not (name_tag and period_tag and img_tag):\n",
    "                    continue\n",
    "\n",
    "                event_name = name_tag.get_text(strip=True)\n",
    "                period = period_tag.get_text(strip=True)\n",
    "                img_url = img_tag.get('src') or img_tag.get('data-src')\n",
    "\n",
    "                if not img_url:\n",
    "                    continue\n",
    "\n",
    "                # URL ì •ê·œí™”\n",
    "                if img_url.startswith('//'):\n",
    "                    img_url = 'https:' + img_url\n",
    "                elif img_url.startswith('/'):\n",
    "                    base_url = '/'.join(url.split('/')[:3])\n",
    "                    img_url = base_url + img_url\n",
    "\n",
    "                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ\n",
    "                img_name = f\"image_{image_count:03d}.jpg\"\n",
    "                try:\n",
    "                    res = requests.get(img_url, timeout=10)\n",
    "                    if res.status_code == 200:\n",
    "                        with open(os.path.join(save_dir, img_name), 'wb') as f:\n",
    "                            f.write(res.content)\n",
    "                        print(f\"ğŸ“¸ ì €ì¥ë¨: {img_name} - {event_name[:30]}\")\n",
    "                    else:\n",
    "                        print(f\"âš ï¸ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ ({res.status_code}): {img_url}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"âŒ ì´ë¯¸ì§€ ì €ì¥ ì‹¤íŒ¨: {e}\")\n",
    "\n",
    "                data.append({\n",
    "                    'ì´ë¯¸ì§€ëª…': img_name,\n",
    "                    'ì´ë²¤íŠ¸ëª…': event_name,\n",
    "                    'ì¦ì •í’ˆ': '',\n",
    "                    'ê¸°ê°„': period\n",
    "                })\n",
    "                image_count += 1\n",
    "\n",
    "            # ë‹¤ìŒ ë²„íŠ¼ ì²˜ë¦¬\n",
    "            print(\"ğŸ” ë‹¤ìŒ ë²„íŠ¼ ì°¾ëŠ” ì¤‘...\")\n",
    "            next_btn = get_next_button(driver)\n",
    "            \n",
    "            if next_btn:\n",
    "                print(\"âœ… ë‹¤ìŒ ë²„íŠ¼ ë°œê²¬\")\n",
    "                if click_next_safely(next_btn, driver):\n",
    "                    # í˜ì´ì§€ ë³€ê²½ í™•ì¸\n",
    "                    time.sleep(3)\n",
    "                    new_page = get_current_page(driver)\n",
    "                    print(f\"ğŸ“„ í˜ì´ì§€ ë³€ê²½: {cur_page} â†’ {new_page}\")\n",
    "                    \n",
    "                    # í˜ì´ì§€ê°€ ë³€ê²½ë˜ì§€ ì•Šì•˜ê±°ë‚˜ ë’¤ë¡œ ê°”ë‹¤ë©´ ì¢…ë£Œ\n",
    "                    if new_page <= cur_page and new_page != -1:\n",
    "                        print(\"ğŸ“Œ í˜ì´ì§€ê°€ ì§„í–‰ë˜ì§€ ì•ŠìŒ. ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                        break\n",
    "                else:\n",
    "                    print(\"âŒ ë‹¤ìŒ ë²„íŠ¼ í´ë¦­ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                    break\n",
    "            else:\n",
    "                print(\"ğŸ“Œ ë‹¤ìŒ ë²„íŠ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ í˜ì´ì§€ë¡œ íŒë‹¨í•˜ì—¬ ì¢…ë£Œí•©ë‹ˆë‹¤.\")\n",
    "                \n",
    "                # ë””ë²„ê¹…: í˜ì´ì§€ë„¤ì´ì…˜ êµ¬ì¡° ì¶œë ¥\n",
    "                try:\n",
    "                    print(\"\\nğŸ” í˜ì´ì§€ë„¤ì´ì…˜ ë””ë²„ê¹… ì •ë³´:\")\n",
    "                    # í˜„ì¬ í˜ì´ì§€ ì •ë³´\n",
    "                    current_page_elem = driver.find_element(By.CSS_SELECTOR, 'a[aria-current=\"page\"]')\n",
    "                    print(f\"í˜„ì¬ í˜ì´ì§€: {current_page_elem.text}\")\n",
    "                    \n",
    "                    # ëª¨ë“  í˜ì´ì§€ ë§í¬ ì¶œë ¥\n",
    "                    page_links = driver.find_elements(By.CSS_SELECTOR, 'a.pagination_page')\n",
    "                    page_numbers = [link.text for link in page_links if link.text.isdigit()]\n",
    "                    print(f\"ì‚¬ìš© ê°€ëŠ¥í•œ í˜ì´ì§€: {', '.join(page_numbers)}\")\n",
    "                    \n",
    "                    # ë‹¤ìŒ/ë§ˆì§€ë§‰ ë²„íŠ¼ ìƒíƒœ í™•ì¸\n",
    "                    try:\n",
    "                        next_btn_elem = driver.find_element(By.CSS_SELECTOR, 'a.pagination_btn--next')\n",
    "                        print(f\"ë‹¤ìŒ ë²„íŠ¼ ì¡´ì¬: {next_btn_elem.is_displayed()}, í™œì„±í™”: {next_btn_elem.is_enabled()}\")\n",
    "                        print(f\"ë‹¤ìŒ ë²„íŠ¼ href: {next_btn_elem.get_attribute('href')}\")\n",
    "                    except:\n",
    "                        print(\"ë‹¤ìŒ ë²„íŠ¼ ì—†ìŒ\")\n",
    "                    \n",
    "                    try:\n",
    "                        last_btn_elem = driver.find_element(By.CSS_SELECTOR, 'a.pagination_btn--last')\n",
    "                        print(f\"ë§ˆì§€ë§‰ ë²„íŠ¼ ì¡´ì¬: {last_btn_elem.is_displayed()}, í™œì„±í™”: {last_btn_elem.is_enabled()}\")\n",
    "                    except:\n",
    "                        print(\"ë§ˆì§€ë§‰ ë²„íŠ¼ ì—†ìŒ\")\n",
    "                        \n",
    "                except Exception as debug_e:\n",
    "                    print(f\"ë””ë²„ê¹… ì¤‘ ì˜¤ë¥˜: {debug_e}\")\n",
    "                    # ê¸°ë³¸ í˜ì´ì§€ë„¤ì´ì…˜ HTML ì¶œë ¥\n",
    "                    try:\n",
    "                        pagination_elements = driver.find_elements(\n",
    "                            By.XPATH, \n",
    "                            '//*[contains(@class, \"pagination\")]'\n",
    "                        )\n",
    "                        for elem in pagination_elements:\n",
    "                            print(\"í˜ì´ì§€ë„¤ì´ì…˜ HTML:\", elem.get_attribute('outerHTML')[:500])\n",
    "                    except:\n",
    "                        print(\"í˜ì´ì§€ë„¤ì´ì…˜ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "                \n",
    "                break\n",
    "            \n",
    "            page_count += 1\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"âŒ í¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        \n",
    "    finally:\n",
    "        driver.quit()\n",
    "        \n",
    "        if data:\n",
    "            df = pd.DataFrame(data)\n",
    "            df = df[['ì´ë¯¸ì§€ëª…', 'ì´ë²¤íŠ¸ëª…', 'ì¦ì •í’ˆ', 'ê¸°ê°„']]\n",
    "            df.to_csv('ì´ë²¤íŠ¸ì •ë³´2.csv', index=False, encoding='utf-8-sig')\n",
    "            print(f\"\\nâœ… í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(df)}ê±´ ì €ì¥ â†’ ì´ë²¤íŠ¸ì •ë³´2.csv\")\n",
    "            print(f\"ğŸ“Š ì²˜ë¦¬ëœ í˜ì´ì§€: {sorted(processed_pages)}\")\n",
    "        else:\n",
    "            print(\"âŒ ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "# ì‹¤í–‰\n",
    "if __name__ == \"__main__\":\n",
    "    crawl_event_page(\"https://www.ypbooks.co.kr/event/online/event-list?status=2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cde0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ì œë¯¸ë‚˜ì´ë¡œ ì´ë¯¸ì§€ ë‚´ ì •ë³´ ì¶”ì¶œ\n",
    "\n",
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "\n",
    "# API í‚¤ ëª©ë¡\n",
    "API_KEYS = [\n",
    "    \"AIzaSyBcHB5SD3c5RyjVFKuuT0_Erwv6mCM3kjw\",\n",
    "    \"AIzaSyB03zq8mm1KFOG46lbif0xEWGr81Ta0RDw\",\n",
    "    \"AIzaSyDIS5FvvjR3E87SYW2KQJeNBAoNL9Eunuc\"\n",
    "]\n",
    "key_index = 0  # í˜„ì¬ í‚¤ ì¸ë±ìŠ¤\n",
    "\n",
    "def init_gemini(api_key):\n",
    "    genai.configure(api_key=api_key)\n",
    "    return genai.GenerativeModel('gemini-2.0-flash-001')\n",
    "\n",
    "model = init_gemini(API_KEYS[key_index])\n",
    "\n",
    "def switch_key():\n",
    "    global key_index, model\n",
    "    key_index = (key_index + 1) % len(API_KEYS)\n",
    "    print(f\"âš ï¸ í‚¤ êµì²´ë¨ â†’ {key_index+1}ë²ˆì§¸ API í‚¤ ì‚¬ìš©\")\n",
    "    model = init_gemini(API_KEYS[key_index])\n",
    "\n",
    "def chat_with_gemini(model, prompt, image_path=None, retry=3):\n",
    "    for attempt in range(retry):\n",
    "        try:\n",
    "            if image_path:\n",
    "                img = Image.open(image_path)\n",
    "                response = model.generate_content([prompt, img])\n",
    "            else:\n",
    "                response = model.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"ğŸ”¥ ì˜¤ë¥˜ ë°œìƒ: {str(e)[:50]}...\")\n",
    "            switch_key()\n",
    "    return \"[ERROR] ëª¨ë“  API í‚¤ ì‹¤íŒ¨\"  # âœ… ì—¬ê¸´ ê·¸ëŒ€ë¡œ OK\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d4ca1c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '''ì´ë¯¸ì§€ì— ì íŒ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ì´ë²¤íŠ¸ì˜ ì¦ì •ë‚´ìš©ë§Œ ì¶”ì¶œí•´ì¤˜.\n",
    "\n",
    "ë‹¤ìŒê³¼ ê°™ì€ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ì •ë¦¬í•´ì¤˜:\n",
    "[{\"ì¦ì •ë‚´ìš©\": \"\"}]\n",
    "\n",
    "ì£¼ì˜: jsonì´ë¼ëŠ” ë‹¨ì–´ë¥¼ ì¶œë ¥í•˜ì§€ ë§ê³ , ìœ„ì™€ ê°™ì€ í˜•ì‹ ê·¸ëŒ€ë¡œ ë°˜í™˜í•´ì¤˜.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24485975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# ì´ë¯¸ì§€ê°€ ìˆëŠ” í´ë” ê²½ë¡œ (ë…¸íŠ¸ë¶ê³¼ ê°™ì€ í´ë”ë¼ë©´ '.')\n",
    "folder = '.'\n",
    "\n",
    "# ì´ë¯¸ì§€ í™•ì¥ì í•„í„°ë§í•´ì„œ ë¦¬ìŠ¤íŠ¸ ë§Œë“¤ê¸°\n",
    "image_files = [f for f in os.listdir(folder) if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# ë°˜ë³µí•´ì„œ ì²˜ë¦¬\n",
    "for filename in image_files:\n",
    "    print(f'ğŸ–¼ï¸ ì²˜ë¦¬ ì¤‘: {filename}')\n",
    "    reply = chat_with_gemini(model, prompt, filename)\n",
    "    print(reply)\n",
    "    print('-' * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e79b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "# 1. í…ìŠ¤íŠ¸ íŒŒì¼ ì½ê¸°\n",
    "with open(\"ì˜í’ì´ë¯¸ì§€í¬ë¡¤ë§.txt\", \"r\", encoding=\"utf-8-sig\") as f:\n",
    "    raw_text = f.read()\n",
    "\n",
    "# 2. ê²°ê³¼ ì €ì¥ìš©\n",
    "results = {}\n",
    "\n",
    "# 3. ë¸”ë¡ ê¸°ì¤€ìœ¼ë¡œ ë¶„í• \n",
    "blocks = raw_text.split(\"ğŸ–¼ï¸ ì²˜ë¦¬ ì¤‘: \")\n",
    "for block in blocks:\n",
    "    if not block.strip():\n",
    "        continue\n",
    "\n",
    "    lines = block.strip().split('\\n')\n",
    "    image_line = lines[0].strip()\n",
    "    image_name = image_line if image_line.endswith(\".jpg\") else None\n",
    "\n",
    "    if not image_name:\n",
    "        continue\n",
    "\n",
    "    # JSON-like ë¸”ë¡ ì°¾ê¸°\n",
    "    json_match = re.search(r'\\[.*?\\]', block, re.DOTALL)\n",
    "    if json_match:\n",
    "        try:\n",
    "            json_data = json.loads(json_match.group())\n",
    "            if isinstance(json_data, list) and len(json_data) > 0:\n",
    "                first_item = json_data[0]\n",
    "                content = first_item.get(\"ì¦ì •ë‚´ìš©\", \"\") or \"\"\n",
    "                results[image_name] = content\n",
    "            else:\n",
    "                results[image_name] = \"\"\n",
    "        except:\n",
    "            results[image_name] = \"\"\n",
    "    else:\n",
    "        results[image_name] = \"\"\n",
    "\n",
    "# 4. ê²°ê³¼ ì €ì¥\n",
    "with open(\"ì˜í’ì´ë¯¸ì§€í¬ë¡¤ë§.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    json.dump(results, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… ì´ {len(results)}ê°œ ì´ë¯¸ì§€ ì •ì œ ì™„ë£Œ â†’ ì˜í’ì´ë¯¸ì§€í¬ë¡¤ë§.json ì €ì¥ë¨\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14dc9724",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ë§µí•‘ì¤€ë¹„\n",
    "\n",
    "import json\n",
    "\n",
    "with open('ì˜í’ì´ë¯¸ì§€í¬ë¡¤ë§.json', 'r', encoding='utf-8-sig') as f:\n",
    "\tdata = json.load(f)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc62344",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dict = {}\n",
    "\n",
    "for key, value in data.items():\n",
    "    # ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ì¶œ\n",
    "    match = re.search(r'image_\\d+\\.jpg', key)\n",
    "    \n",
    "    # ì •ìƒì ì¸ ì´ë¯¸ì§€ëª…ì´ê³ , ê°’ë„ ë¹„ì •ìƒ ì‘ë‹µì´ ì•„ë‹ ë•Œë§Œ ì¶”ê°€\n",
    "    if match and value and 'ì˜¤ë¥˜ ë°œìƒ' not in value and 'ì´ë¯¸ì§€ì— ì¦ì • ë‚´ìš©ì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤' not in value:\n",
    "        cleaned_key = match.group(0)\n",
    "        cleaned_dict[cleaned_key] = value\n",
    "        \n",
    "cleaned_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1729182d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "yp_event = pd.read_csv('ì´ë²¤íŠ¸ì •ë³´2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215dc4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map ì ìš©\n",
    "yp_event['ì¦ì •ë‚´ìš©'] = yp_event['ì´ë¯¸ì§€ëª…'].map(cleaned_dict)\n",
    "yp_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a59dc416",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_event.drop('ì¦ì •í’ˆ', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55ae7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_event.to_csv('ì˜í’ì´ë²¤íŠ¸.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23f95f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# 1. í…ìŠ¤íŠ¸ ë¡œë“œ\n",
    "with open('ì˜í’ì´ë¯¸ì§€í¬ë¡¤ë§.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# 2. ë¸”ë¡ ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ê¸°\n",
    "blocks = text.split('ğŸ–¼ï¸ ì²˜ë¦¬ ì¤‘: ')[1:]  # ì²« ë¸”ë¡ì€ ë¹„ì–´ ìˆìœ¼ë‹ˆ ì œì™¸\n",
    "\n",
    "# 3. ì˜¤ë¥˜ë‚œ ì´ë¯¸ì§€ë§Œ ì¶”ì¶œ\n",
    "failed_images = []\n",
    "\n",
    "for block in blocks:\n",
    "    lines = block.strip().split('\\n')\n",
    "    image_line = lines[0].strip()\n",
    "    image_name = image_line if image_line.endswith('.jpg') else None\n",
    "\n",
    "    # ì „ì²´ í‚¤ ì‹¤íŒ¨ íŒ¨í„´ í¬í•¨ ì—¬ë¶€ í™•ì¸\n",
    "    if '[ERROR] ëª¨ë“  API í‚¤ ì‹¤íŒ¨' in block:\n",
    "        failed_images.append(image_name)\n",
    "\n",
    "print(f\"âŒ ì´ ì‹¤íŒ¨ ì´ë¯¸ì§€ ìˆ˜: {len(failed_images)}\")\n",
    "print(failed_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c051d599",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from PIL import Image\n",
    "import os\n",
    "import json\n",
    "import time\n",
    "\n",
    "# -----------------------\n",
    "# 1. ì´ˆê¸°í™”\n",
    "API_KEYS = [\n",
    "    \"AIzaSyBcHB5SD3c5RyjVFKuuT0_Erwv6mCM3kjw\",\n",
    "    \"AIzaSyB03zq8mm1KFOG46lbif0xEWGr81Ta0RDw\",\n",
    "    \"AIzaSyDIS5FvvjR3E87SYW2KQJeNBAoNL9Eunuc\"\n",
    "]\n",
    "\n",
    "def init_gemini(api_key):\n",
    "    genai.configure(api_key=api_key)\n",
    "    return genai.GenerativeModel('gemini-2.0-flash-001')\n",
    "\n",
    "# -----------------------\n",
    "# 2. ì‘ë‹µ í•¨ìˆ˜ (íŒŒì¼ ì¡´ì¬ í™•ì¸ ì¶”ê°€)\n",
    "def chat_with_gemini(model, prompt, image_path):\n",
    "    try:\n",
    "        # íŒŒì¼ ì¡´ì¬ í™•ì¸\n",
    "        if not os.path.exists(image_path):\n",
    "            return f\"[ERROR] íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {image_path}\"\n",
    "        \n",
    "        img = Image.open(image_path)\n",
    "        response = model.generate_content([prompt, img])\n",
    "        return response.text\n",
    "    except Exception as e:\n",
    "        return f\"[ERROR] {e}\"\n",
    "\n",
    "# -----------------------\n",
    "# 3. í”„ë¡¬í”„íŠ¸\n",
    "def get_prompt(image_name):\n",
    "    return f'''\n",
    "ì´ë¯¸ì§€ì—ì„œ ì¦ì • ë‚´ìš©ì„ ì¶”ì¶œí•´ì¤˜.\n",
    "\n",
    "ë‹¤ìŒ í˜•ì‹ì²˜ëŸ¼ ë°˜í™˜í•´ì¤˜:\n",
    "{{\n",
    "  \"ì´ë¯¸ì§€ëª…\": \"{image_name}\",\n",
    "  \"ì¦ì •ë‚´ìš©\": \"...\"\n",
    "}}\n",
    "\n",
    "ì •ë³´ê°€ ì—†ìœ¼ë©´ ì¦ì •ë‚´ìš©ì€ ë¹ˆ ë¬¸ìì—´(\"\")ë¡œ í‘œì‹œí•´ì¤˜.\n",
    "ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ë‹µë³€í•˜ê³ , ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì—†ì´ ë°˜í™˜í•´ì¤˜.\n",
    "'''\n",
    "\n",
    "# -----------------------\n",
    "# 4. ì‹¤íŒ¨ ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (ì˜ˆì‹œ)\n",
    "failed_images\n",
    "\n",
    "# -----------------------\n",
    "# 5. ì´ë¯¸ì§€ í´ë” ë° íŒŒì¼ í™•ì¸\n",
    "image_folder = \".\"  # í˜„ì¬ ë””ë ‰í† ë¦¬ (ë…¸íŠ¸ë¶ê³¼ ê°™ì€ ìœ„ì¹˜)\n",
    "\n",
    "# ì‹¤ì œ ì¡´ì¬í•˜ëŠ” ì´ë¯¸ì§€ íŒŒì¼ë§Œ í•„í„°ë§\n",
    "existing_images = []\n",
    "missing_images = []\n",
    "\n",
    "for image_name in failed_images:\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    if os.path.exists(image_path):\n",
    "        existing_images.append(image_name)\n",
    "    else:\n",
    "        missing_images.append(image_name)\n",
    "\n",
    "print(f\"âœ… ì¡´ì¬í•˜ëŠ” ì´ë¯¸ì§€: {len(existing_images)}ê°œ\")\n",
    "print(f\"âŒ ì—†ëŠ” ì´ë¯¸ì§€: {len(missing_images)}ê°œ\")\n",
    "\n",
    "if missing_images:\n",
    "    print(\"ì—†ëŠ” ì´ë¯¸ì§€ë“¤:\")\n",
    "    for img in missing_images:\n",
    "        print(f\"  - {img}\")\n",
    "\n",
    "if not existing_images:\n",
    "    print(\"ì²˜ë¦¬í•  ìˆ˜ ìˆëŠ” ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.\")\n",
    "    exit()\n",
    "\n",
    "# -----------------------\n",
    "# 6. Gemini ìˆœí™˜ ë° ì‹¤í–‰\n",
    "result_dict = {}\n",
    "api_index = 0\n",
    "model = init_gemini(API_KEYS[api_index])\n",
    "\n",
    "for i, image_name in enumerate(existing_images, 1):\n",
    "    image_path = os.path.join(image_folder, image_name)\n",
    "    print(f\"ğŸ”„ [{i}/{len(existing_images)}] ì¬ì‹œë„ ì¤‘: {image_name}\")\n",
    "\n",
    "    success = False\n",
    "    for attempt in range(len(API_KEYS)):\n",
    "        reply = chat_with_gemini(model, get_prompt(image_name), image_path)\n",
    "\n",
    "        if \"[ERROR]\" not in reply:\n",
    "            success = True\n",
    "            break\n",
    "        else:\n",
    "            print(f\"âš ï¸ ì˜¤ë¥˜ (ì‹œë„ {attempt+1}): {reply[:60]}...\")\n",
    "            if attempt < len(API_KEYS) - 1:  # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë¼ë©´\n",
    "                print(\"â†’ ë‹¤ìŒ í‚¤ë¡œ ì „í™˜\")\n",
    "                api_index = (api_index + 1) % len(API_KEYS)\n",
    "                model = init_gemini(API_KEYS[api_index])\n",
    "                time.sleep(1)\n",
    "\n",
    "    # ì‘ë‹µ ì²˜ë¦¬\n",
    "    if success:\n",
    "        try:\n",
    "            # ì›ë³¸ ì‘ë‹µ í™•ì¸ìš© ì¶œë ¥ (ë””ë²„ê¹…)\n",
    "            print(f\"ğŸ“ ì›ë³¸ ì‘ë‹µ (ì²˜ìŒ 200ì): {reply[:200]}\")\n",
    "            \n",
    "            # JSON íŒŒì‹± ê°œì„ \n",
    "            clean = reply.strip().strip('` \\n')\n",
    "            if clean.startswith('```json'):\n",
    "                clean = clean[7:]\n",
    "            if clean.startswith('```'):\n",
    "                clean = clean[3:]\n",
    "            if clean.endswith('```'):\n",
    "                clean = clean[:-3]\n",
    "            clean = clean.strip()\n",
    "            \n",
    "            print(f\"ğŸ”§ ì •ì œëœ ì‘ë‹µ: {clean[:100]}\")\n",
    "            \n",
    "            # ì—¬ëŸ¬ ë°©ë²•ìœ¼ë¡œ íŒŒì‹± ì‹œë„\n",
    "            parsed_data = None\n",
    "            \n",
    "            # ë°©ë²• 1: JSON íŒŒì‹±\n",
    "            try:\n",
    "                parsed_data = json.loads(clean)\n",
    "                print(\"âœ… JSON íŒŒì‹± ì„±ê³µ\")\n",
    "            except json.JSONDecodeError:\n",
    "                print(\"âŒ JSON íŒŒì‹± ì‹¤íŒ¨, ë‹¤ë¥¸ ë°©ë²• ì‹œë„\")\n",
    "            \n",
    "            # ë°©ë²• 2: ì¤‘ê´„í˜¸ ì°¾ì•„ì„œ ì¶”ì¶œ\n",
    "            if not parsed_data:\n",
    "                try:\n",
    "                    import re\n",
    "                    # ì¤‘ê´„í˜¸ë¡œ ë‘˜ëŸ¬ì‹¸ì¸ ë¶€ë¶„ ì°¾ê¸°\n",
    "                    match = re.search(r'\\{[^}]*\\}', clean, re.DOTALL)\n",
    "                    if match:\n",
    "                        json_str = match.group(0)\n",
    "                        parsed_data = json.loads(json_str)\n",
    "                        print(\"âœ… ì •ê·œì‹ JSON íŒŒì‹± ì„±ê³µ\")\n",
    "                except:\n",
    "                    print(\"âŒ ì •ê·œì‹ JSON íŒŒì‹± ì‹¤íŒ¨\")\n",
    "            \n",
    "            # ë°©ë²• 3: eval ì‹œë„ (ë§ˆì§€ë§‰ ìˆ˜ë‹¨)\n",
    "            if not parsed_data:\n",
    "                try:\n",
    "                    parsed_data = eval(clean)\n",
    "                    print(\"âœ… eval íŒŒì‹± ì„±ê³µ\")\n",
    "                except:\n",
    "                    print(\"âŒ eval íŒŒì‹± ì‹¤íŒ¨\")\n",
    "            \n",
    "            # ë°©ë²• 4: ë‹¨ìˆœ í…ìŠ¤íŠ¸ì—ì„œ ì¦ì •ë‚´ìš© ì¶”ì¶œ\n",
    "            if not parsed_data:\n",
    "                try:\n",
    "                    # \"ì¦ì •ë‚´ìš©\"ì´ë¼ëŠ” í‚¤ì›Œë“œ ë’¤ì˜ ë‚´ìš© ì¶”ì¶œ\n",
    "                    if \"ì¦ì •ë‚´ìš©\" in reply:\n",
    "                        lines = reply.split('\\n')\n",
    "                        for line in lines:\n",
    "                            if \"ì¦ì •ë‚´ìš©\" in line and \":\" in line:\n",
    "                                content = line.split(\":\", 1)[1].strip().strip('\"\\'')\n",
    "                                result_dict[image_name] = content\n",
    "                                print(f\"âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ: {content[:50]}\")\n",
    "                                break\n",
    "                        else:\n",
    "                            result_dict[image_name] = reply.strip()  # ì „ì²´ ì‘ë‹µ ì €ì¥\n",
    "                            print(\"âš ï¸ í‚¤ì›Œë“œ ì°¾ê¸° ì‹¤íŒ¨, ì „ì²´ ì‘ë‹µ ì €ì¥\")\n",
    "                    else:\n",
    "                        result_dict[image_name] = reply.strip()  # ì „ì²´ ì‘ë‹µ ì €ì¥\n",
    "                        print(\"âš ï¸ 'ì¦ì •ë‚´ìš©' í‚¤ì›Œë“œ ì—†ìŒ, ì „ì²´ ì‘ë‹µ ì €ì¥\")\n",
    "                except:\n",
    "                    result_dict[image_name] = \"\"\n",
    "                    print(\"âŒ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨\")\n",
    "            else:\n",
    "                # ì •ìƒ íŒŒì‹±ëœ ê²½ìš°\n",
    "                if isinstance(parsed_data, dict):\n",
    "                    # ì´ë¯¸ì§€ëª…ì„ ì‹¤ì œ íŒŒì¼ëª…ìœ¼ë¡œ ê°•ì œ êµì²´\n",
    "                    parsed_data[\"ì´ë¯¸ì§€ëª…\"] = image_name\n",
    "                    result_dict[image_name] = parsed_data.get(\"ì¦ì •ë‚´ìš©\", \"\")\n",
    "                else:\n",
    "                    result_dict[image_name] = str(parsed_data)\n",
    "                print(f\"âœ… íŒŒì‹± ì„±ê³µ: {image_name}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸ ì „ì²´ íŒŒì‹± ê³¼ì • ì‹¤íŒ¨: {e}\")\n",
    "            # ì›ë³¸ ì‘ë‹µì´ë¼ë„ ì €ì¥\n",
    "            result_dict[image_name] = reply if reply else \"\"\n",
    "    else:\n",
    "        print(f\"âŒ ëª¨ë“  ì‹œë„ ì‹¤íŒ¨: {image_name}\")\n",
    "        result_dict[image_name] = \"\"\n",
    "\n",
    "    time.sleep(4)\n",
    "\n",
    "# -----------------------\n",
    "# 7. ì €ì¥ ë° í†µê³„\n",
    "with open(\"ì¬ì‹œë„_ê²°ê³¼.json\", \"w\", encoding=\"utf-8-sig\") as f:\n",
    "    json.dump(result_dict, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# í†µê³„ ì¶œë ¥\n",
    "success_count = sum(1 for v in result_dict.values() if v)\n",
    "print(f\"\\nğŸ“Š ì¬ì‹œë„ ê²°ê³¼:\")\n",
    "print(f\"  - ì „ì²´ ì²˜ë¦¬: {len(result_dict)}ê°œ\")\n",
    "print(f\"  - ì„±ê³µ: {success_count}ê°œ\")\n",
    "print(f\"  - ì‹¤íŒ¨: {len(result_dict) - success_count}ê°œ\")\n",
    "print(f\"  - ì—†ëŠ” íŒŒì¼: {len(missing_images)}ê°œ\")\n",
    "print(\"âœ… ì¬ì‹œë„ ì™„ë£Œ â†’ ì¬ì‹œë„_ê²°ê³¼.json ì €ì¥ë¨\")\n",
    "\n",
    "# ì‹¤íŒ¨í•œ ì´ë¯¸ì§€ ëª©ë¡ë„ ì €ì¥\n",
    "if missing_images:\n",
    "    with open(\"ì—†ëŠ”_íŒŒì¼_ëª©ë¡.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        for img in missing_images:\n",
    "            f.write(f\"{img}\\n\")\n",
    "    print(\"ğŸ“ ì—†ëŠ” íŒŒì¼ ëª©ë¡ â†’ ì—†ëŠ”_íŒŒì¼_ëª©ë¡.txt ì €ì¥ë¨\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09aed85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('ì¬ì‹œë„_ê²°ê³¼.json', 'r', encoding='utf-8-sig') as f:\n",
    "\tdata2 = json.load(f)\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7a4003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ê¸°ì¡´ê³¼ ì¬ì‹œë„ ê²°ê³¼ í•©ì¹˜ê¸°\n",
    "full_dict = {**data, **data2}  # retry_dict ê°’ì´ ìš°ì„  ë®ì–´ì§\n",
    "full_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5134ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_dict2 = {}\n",
    "\n",
    "for key, value in full_dict.items():\n",
    "    # ì´ë¯¸ì§€ íŒŒì¼ëª… ì¶”ì¶œ\n",
    "    match = re.search(r'image_\\d+\\.jpg', key)\n",
    "    \n",
    "    # ì •ìƒì ì¸ ì´ë¯¸ì§€ëª…ì´ê³ , ê°’ë„ ë¹„ì •ìƒ ì‘ë‹µì´ ì•„ë‹ ë•Œë§Œ ì¶”ê°€\n",
    "    if match and value and 'ì˜¤ë¥˜ ë°œìƒ' not in value and 'ì´ë¯¸ì§€ì— ì¦ì • ë‚´ìš©ì— ëŒ€í•œ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤' not in value:\n",
    "        cleaned_key = match.group(0)\n",
    "        cleaned_dict2[cleaned_key] = value\n",
    "        \n",
    "cleaned_dict2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e224e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yp_event = pd.read_csv('ì˜í’ì´ë²¤íŠ¸.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8bdc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map ì ìš©\n",
    "yp_event['ì¦ì •ë‚´ìš©'] = yp_event['ì´ë¯¸ì§€ëª…'].map(cleaned_dict2)\n",
    "yp_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbbbb1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_event.to_csv('ì˜í’ì´ë²¤íŠ¸.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca74fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "yp_event = pd.read_csv('ì˜í’ì´ë²¤íŠ¸.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ed035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_event = yp_event[['ì´ë²¤íŠ¸ëª…', 'ì¦ì •ë‚´ìš©', 'ê¸°ê°„', 'ì´ë¯¸ì§€ëª…']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a4530c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02846879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. NaNì¸ í–‰ë“¤ì˜ ì¸ë±ìŠ¤ë¥¼ ì¶”ì¶œ\n",
    "NaN_idx = yp_event[yp_event['ì¦ì •ë‚´ìš©'].isna()].index\n",
    "\n",
    "# 2. í•´ë‹¹ ì¸ë±ìŠ¤ë¥¼ drop\n",
    "yp_event = yp_event.drop(index=NaN_idx)\n",
    "\n",
    "yp_event.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479d528",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_event[yp_event['ì¦ì •ë‚´ìš©'] == 'ì¶œê°„ê¸°ë…']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1fa1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_event = yp_event.drop([6, 48, 80, 141, 247])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb4d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_event.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210700de",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp_event.to_csv('ì˜í’ì´ë²¤íŠ¸.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
